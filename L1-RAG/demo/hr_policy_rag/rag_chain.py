"""
RAGé“¾æ¨¡å—ï¼šå®ç°å®Œæ•´çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæµç¨‹

æ ¸å¿ƒçŸ¥è¯†ç‚¹ï¼š
1. RAGæµç¨‹ï¼šæ£€ç´¢(Retrieval) + ç”Ÿæˆ(Generation)
2. Promptå·¥ç¨‹ï¼šè®¾è®¡æœ‰æ•ˆçš„æç¤ºè¯æ¨¡æ¿
3. ä¸Šä¸‹æ–‡å¢å¼ºï¼šå°†æ£€ç´¢ç»“æœæ³¨å…¥åˆ°ç”Ÿæˆæ¨¡å‹çš„ä¸Šä¸‹æ–‡ä¸­
"""
import os
from typing import List
from langchain.schema import Document
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser
from vector_store import VectorStoreManager


class RAGChain:
    """RAGé“¾ï¼šå®ç°æ£€ç´¢å¢å¼ºç”Ÿæˆ"""
    
    def __init__(self, vector_store_manager: VectorStoreManager, model_name: str = "gpt-3.5-turbo"):
        """
        åˆå§‹åŒ–RAGé“¾
        
        Args:
            vector_store_manager: å‘é‡å­˜å‚¨ç®¡ç†å™¨
            model_name: ä½¿ç”¨çš„LLMæ¨¡å‹åç§°
        """
        self.vector_store_manager = vector_store_manager
        self.llm = ChatOpenAI(
            model=model_name,
            temperature=0.7,  # æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶ç”Ÿæˆçš„éšæœºæ€§
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # å®šä¹‰Promptæ¨¡æ¿
        # è¿™æ˜¯RAGçš„æ ¸å¿ƒï¼šå°†æ£€ç´¢åˆ°çš„æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡æ³¨å…¥åˆ°Promptä¸­
        self.prompt_template = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„HRåŠ©æ‰‹ï¼Œè´Ÿè´£å›ç­”å‘˜å·¥å…³äºå…¬å¸HRåˆ¶åº¦çš„é—®é¢˜ã€‚

è¯·ä¸¥æ ¼åŸºäºä»¥ä¸‹æä¾›çš„å…¬å¸åˆ¶åº¦æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜"æš‚æ— ç›¸å…³è§„å®š"ã€‚

å›ç­”è¦æ±‚ï¼š
1. ç­”æ¡ˆå¿…é¡»å‡†ç¡®ã€å®Œæ•´
2. å¿…é¡»æ ‡æ³¨ä¿¡æ¯æ¥æºï¼ˆå¦‚"æ ¹æ®ã€Šå‘˜å·¥æ‰‹å†Œã€‹ç¬¬Xç« ç¬¬XèŠ‚"ï¼‰
3. ä½¿ç”¨ç®€æ´ã€å‹å¥½çš„è¯­è¨€
4. å¦‚æœæ¶‰åŠå…·ä½“æ•°å­—æˆ–æµç¨‹ï¼Œè¯·è¯¦ç»†è¯´æ˜

å…¬å¸åˆ¶åº¦æ–‡æ¡£å†…å®¹ï¼š
{context}"""),
            ("human", "{question}")
        ])
    
    def format_docs(self, docs: List[Document]) -> str:
        """
        æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸ºå­—ç¬¦ä¸²
        
        Args:
            docs: æ–‡æ¡£åˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–åçš„æ–‡æ¡£å­—ç¬¦ä¸²
        """
        formatted_docs = []
        for i, doc in enumerate(docs, 1):
            source = doc.metadata.get('source', 'unknown')
            chunk_id = doc.metadata.get('chunk_id', 'unknown')
            content = doc.page_content
            
            formatted_docs.append(
                f"[æ–‡æ¡£ç‰‡æ®µ {i} - æ¥æº: {source}, ID: {chunk_id}]\n{content}\n"
            )
        
        return "\n".join(formatted_docs)
    
    def retrieve(self, query: str, k: int = 3) -> List[Document]:
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            k: è¿”å›çš„æ–‡æ¡£æ•°é‡
            
        Returns:
            ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        return self.vector_store_manager.similarity_search(query, k=k)
    
    def generate(self, query: str, context: str) -> str:
        """
        åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå›ç­”
        
        Args:
            query: ç”¨æˆ·é—®é¢˜
            context: æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸Šä¸‹æ–‡
            
        Returns:
            ç”Ÿæˆçš„å›ç­”
        """
        # æ„å»ºå®Œæ•´çš„Prompt
        messages = self.prompt_template.format_messages(
            context=context,
            question=query
        )
        
        # è°ƒç”¨LLMç”Ÿæˆå›ç­”
        response = self.llm.invoke(messages)
        return response.content
    
    def invoke(self, query: str, k: int = 3) -> dict:
        """
        æ‰§è¡Œå®Œæ•´çš„RAGæµç¨‹
        
        Args:
            query: ç”¨æˆ·é—®é¢˜
            k: æ£€ç´¢çš„æ–‡æ¡£æ•°é‡
            
        Returns:
            åŒ…å«é—®é¢˜ã€æ£€ç´¢ç»“æœã€å›ç­”çš„å­—å…¸
        """
        # æ­¥éª¤1: æ£€ç´¢ç›¸å…³æ–‡æ¡£
        print(f"ğŸ” æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£...")
        retrieved_docs = self.retrieve(query, k=k)
        
        # æ­¥éª¤2: æ ¼å¼åŒ–æ–‡æ¡£ä¸ºä¸Šä¸‹æ–‡
        context = self.format_docs(retrieved_docs)
        
        # æ­¥éª¤3: ç”Ÿæˆå›ç­”
        print(f"ğŸ¤– æ­£åœ¨ç”Ÿæˆå›ç­”...")
        answer = self.generate(query, context)
        
        return {
            "question": query,
            "retrieved_docs": retrieved_docs,
            "context": context,
            "answer": answer
        }
    
    def create_chain(self, k: int = 3):
        """
        åˆ›å»ºLangChainé£æ ¼çš„RAGé“¾ï¼ˆä½¿ç”¨é“¾å¼è°ƒç”¨ï¼‰
        
        Args:
            k: æ£€ç´¢çš„æ–‡æ¡£æ•°é‡
            
        Returns:
            RAGé“¾å¯¹è±¡
        """
        # å®šä¹‰æ£€ç´¢å‡½æ•°
        def retrieve_docs(query: str) -> str:
            docs = self.vector_store_manager.similarity_search(query, k=k)
            return self.format_docs(docs)
        
        # æ„å»ºRAGé“¾
        # 1. æ¥æ”¶ç”¨æˆ·é—®é¢˜
        # 2. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        # 3. æ ¼å¼åŒ–æ–‡æ¡£ä¸ºä¸Šä¸‹æ–‡
        # 4. æ³¨å…¥åˆ°Promptä¸­
        # 5. è°ƒç”¨LLMç”Ÿæˆå›ç­”
        # 6. è§£æè¾“å‡ºä¸ºå­—ç¬¦ä¸²
        chain = (
            {
                "context": RunnablePassthrough() | retrieve_docs,
                "question": RunnablePassthrough()
            }
            | self.prompt_template
            | self.llm
            | StrOutputParser()
        )
        
        return chain


def demo_rag_chain():
    """æ¼”ç¤ºRAGé“¾åŠŸèƒ½"""
    print("=" * 60)
    print("RAGé“¾æ¨¡å—æ¼”ç¤º")
    print("=" * 60)
    
    from vector_store import VectorStoreManager
    
    # 1. åŠ è½½å‘é‡å­˜å‚¨
    vector_manager = VectorStoreManager()
    storage_path = os.path.join(os.path.dirname(__file__), "storage", "vectorstore")
    
    try:
        vector_manager.load_vector_store(storage_path)
    except FileNotFoundError:
        print("âŒ å‘é‡å­˜å‚¨ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ vector_store.py åˆ›å»ºå‘é‡å­˜å‚¨")
        return
    
    # 2. åˆ›å»ºRAGé“¾
    rag = RAGChain(vector_manager)
    
    # 3. æµ‹è¯•é—®é¢˜
    test_questions = [
        "å¹´å‡å¦‚ä½•ç”³è¯·ï¼Ÿéœ€è¦æå‰å‡ å¤©ï¼Ÿ",
        "äº§å‡æœ‰å¤šå°‘å¤©ï¼Ÿå·¥èµ„æ€ä¹ˆå‘ï¼Ÿ",
        "å·¥èµ„ä»€ä¹ˆæ—¶å€™å‘æ”¾ï¼Ÿ",
        "è¯•ç”¨æœŸæ˜¯å¤šé•¿æ—¶é—´ï¼Ÿ"
    ]
    
    print("\n" + "=" * 60)
    print("RAGé—®ç­”æµ‹è¯•")
    print("=" * 60)
    
    for question in test_questions:
        print(f"\nâ“ é—®é¢˜: {question}")
        print("-" * 60)
        
        result = rag.invoke(question, k=3)
        
        print(f"ğŸ“ å›ç­”:\n{result['answer']}")
        print(f"\nğŸ“š å‚è€ƒæ–‡æ¡£æ•°é‡: {len(result['retrieved_docs'])}")
    
    print("\nâœ… æ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    demo_rag_chain()

