# L1: AI大模型基础知识
## 核心概念
### 1. 人工智能（AI）定义与应用视角
- 定义：通过计算机系统模拟人类智能（如学习、推理、决策）的技术，核心目标是用机器解决复杂问题、优化流程或创造价值。
- 应用视角：无需深究底层数学，将AI视为“工具链”（如ChatGPT生成代码、Claude分析需求），通过调用API或低代码平台快速实现业务目标（如自动化测试、需求拆解）。

### 2. 人工智能演进阶段
| 阶段 | 核心特征 | 代表技术/产品 | 与开发/测试的关联 |
|------|----------|---------------|------------------|
| AI1.0 | 规则驱动、专用领域 | 早期Siri、传统图像识别 | 需手动编写规则，灵活性低，测试以功能验证为主 |
| AI2.0 | 数据驱动、通用能力 | AIGC（GPT-4、Stable Diffusion）、大模型（LLaMA、PaLM） | 开发需聚焦工具链集成，测试需覆盖大模型幻觉、伦理合规（如输出偏见检测） |

### 3. 大模型核心分类与特点
#### （1）生成式人工智能
- 定义：深度学习中快速增长的子集，基于大量原始未标记数据预训练，能“理解”语言/图像并自动生成新内容（文本、图像、代码等）。
- 测试重点：验证生成结果的合理性（如代码安全性、信息准确性）。

#### （2）大语言模型（LLM）
- 定义：专注自然语言处理（NLP），基于Transformer架构，经大规模文本数据集训练，能捕捉语言的语法、语义、语境及文化社会知识。
- 典型应用：文本生成、问答系统、文本分类、机器翻译、对话系统。
- 代表模型：GPT系列（OpenAI）、Bard（Google）、通义千问（阿里云）、DeepSeek（深度求索）。
- 测试重点：幻觉问题（如虚构事实、错误引用）、语义一致性验证。

#### （3）多模态模型
- 定义：可同时处理和理解文本、图像、音频、视频等多源数据，能在模态间建立关联并完成跨模态推理、生成任务。
- 应用场景：视觉问答、图像描述生成、跨模态检索、多媒体内容理解。
- 测试重点：跨模态一致性检查（如语音描述与图像内容匹配度）。

### 4. 大模型与通用人工智能（AGI）的关系
| 主题 | 定义与关系 | 实践方向 |
|------|------------|----------|
| 大模型 | 基于海量数据训练的巨型神经网络，擅长语言理解与内容生成，本质是“概率预测”工具 | 用大模型生成测试用例、自动化脚本（如GPT-4写Python测试代码） |
| AGI | 具备人类全面智能（自主思考、跨领域学习），尚未实现 | 聚焦“专用AGI”（如AI测试工具链的端到端自动化） |
| 二者关系 | 大模型是迈向AGI的阶段性成果，需人类设计任务框架与约束条件 | 掌握“需求→AI指令→交付”的翻译能力（如模糊需求转化为Prompt指令） |

### 5. 大模型训练与使用三阶段
#### （1）预训练（Pre-training）
- 核心：模型学习海量语料的统计规律和一般知识，构建基础认知框架。
- 局限：输出可能不符合人类偏好或存在事实错误（如答非所问）。

#### （2）监督微调（SFT）
- 核心：让模型遵循人类指令回答，通过标注数据优化模型输出的相关性与准确性。
- 作用：修正预训练模型的“偏差”，使其响应更贴合人类需求。

#### （3）基于人类反馈的强化学习（RLHF）
- 核心：对同一问题生成多个答案，人类打分后，模型学习输出高分答案，适配人类偏好。
- 类比：类似员工根据领导/客户反馈调整工作方法，提升满意度。

### 6. 关键底层技术：Transformer架构
- 一句话定义：用“自注意力机制”替代传统RNN的架构，专为高效处理序列数据（如文本）而生，是大模型的核心发动机。

#### （1）核心优势（对比RNN/CNN）
| 对比维度 | RNN/CNN时代 | Transformer时代 |
|----------|-------------|----------------|
| 长文本处理 | 难以捕捉长距离依赖 | 自注意力机制全局关联，支持数万tokens |
| 训练效率 | 串行计算，速度慢 | 并行计算，训练快10倍+ |
| 多模态扩展 | 结构僵化，适配性差 | 架构灵活（ViT处理图像、Whisper处理语音） |

#### （2）核心组件与作用
| 组件 | 作用 | 测试场景示例 |
|------|------|--------------|
| 自注意力机制 | 计算词与词之间的关联权重，动态聚焦重点信息 | 测试模型是否关注关键信息（如合同金额条款） |
| 前馈网络 | 对特征进行非线性变换 | 验证模型复杂逻辑处理能力（如嵌套条件判断） |
| 残差连接 | 防止梯度消失，加速训练 | 测试模型训练稳定性（如微调后性能保持性） |

## 技术栈
### 1. 基础开发工具
- 编程语言：Python（大模型开发主流语言）
- 深度学习框架：PyTorch、TensorFlow（无需深究底层，聚焦API调用）
- 开源工具链：Hugging Face（模型调用、微调、评估）、LangChain（流程编排）
- 智能开发工具：Cursor（智能IDE，支持GPT-4自动补全）、GitHub Copilot（代码框架生成）

### 2. 模型调用与交互工具
| 工具/平台 | 特点 | 适用场景 |
|-----------|------|----------|
| GPT-4（OpenAI） | 多模态、强逻辑推理 | 生成测试代码、分析需求文档 |
| Claude（Anthropic） | 长上下文、伦理约束强 | 合规性审查、测试报告总结 |
| 通义千问（阿里） | 中文优化、企业级服务 | 国内业务场景适配、私有化部署 |
| DeepSeek（深度求索） | 专注代码生成与优化 | 自动化测试脚本开发、性能调优 |

### 3. 评估与测试工具
- 模型评估：RAGAS（上下文相关性、答案忠实度评估）、TruLens（全流程trace可视化）
- 测试框架：Cypress（端到端测试）、Locust（压力测试）、Captum（注意力权重可视化）
- 安全工具：Semgrep（代码静态分析）、Vault（动态密钥管理）

## 最佳实践
### 1. 模型选择策略
- 通用场景：优先选择GPT-4（强逻辑）、Claude（长文本）等成熟模型。
- 中文场景：优先选择文心大模型、通义千问等国产模型（中文优化、合规性强）。
- 代码场景：优先选择DeepSeek、GitHub Copilot（代码生成与优化能力突出）。
- 成本敏感场景：选择开源模型（如ChatGLM-6B）+ 本地化部署（降低API调用成本）。

### 2. 性能优化技巧
- 上下文管理：控制Prompt长度（如GPT-4-32K上限32768 tokens），用tiktoken计算token数。
- 成本控制：通过LangChain的回调功能监控token消耗，避免预算超支。
- 响应速度：使用流式输出（逐词实时返回），提升用户体验。
- 部署优化：采用云服务（AWS Inferentia芯片）降低推理成本，支持CPU推理（小规模场景）。

### 3. 风险与合规应对
| 风险类型 | 具体问题 | 应对策略 |
|----------|----------|----------|
| 技术风险 | 幻觉问题、数据偏差 | 构建幻觉检测工具包，测试数据覆盖长尾场景 |
| 伦理风险 | 算法偏见、输出违规内容 | 设计公平性测试套件，集成内容安全API过滤违规信息 |
| 安全风险 | 敏感信息泄露、Prompt攻击 | 输入数据清洗（正则过滤特殊字符），本地化存储敏感数据 |
| 商业风险 | 算力成本高、知识更新滞后 | 开发云端-边缘协同测试框架，对接动态更新知识库 |

### 4. 基础开发实操指南
#### （1）快速验证Transformer能力
```python
from transformers import pipeline
# 情感分类示例
classifier = pipeline("text-classification")
result = classifier("这个AI测试工具太棒了!")
print(result)  # 输出:[{'label': 'POSITIVE', 'score': 0.999}]
```

#### （2）用大模型生成自动化测试脚本
```python
# Prompt示例：生成登录接口并发测试脚本
prompt = """你是资深测试工程师，请用Python写一个测试登录接口的脚本，包含：
1. 并发请求（10个线程）
2. 响应时间统计
3. 断言响应状态码为200
"""
# 调用GPT-4生成代码后，补充业务逻辑（如接口URL、测试数据）
```

#### （3）大模型专项测试实操
- 长上下文测试：输入1万字文档，验证模型总结是否遗漏关键数据（工具：LangChain文本分割）。
- 多模态测试：输入“CT影像+患者主诉”，验证模型诊断建议合理性（工具：GPT-4V）。
- 幻觉测试：输入虚构概念（如“磁悬浮汽车的量子推进原理”），验证模型是否提示“暂无可靠资料”。