{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG实战教程：HR制度问答系统\n",
        "\n",
        "本Notebook将带你逐步理解RAG的核心概念和实现。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 环境准备\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# 添加项目路径\n",
        "project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
        "sys.path.append(project_root)\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# 检查API密钥\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    print(\"⚠️ 请设置OPENAI_API_KEY环境变量\")\n",
        "else:\n",
        "    print(\"✅ API密钥已配置\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 文档加载与分块\n",
        "\n",
        "### 2.1 为什么需要分块？\n",
        "\n",
        "- LLM有上下文长度限制\n",
        "- 长文档直接向量化会丢失细节\n",
        "- 分块后可以精确检索到相关片段\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from document_loader import DocumentLoader\n",
        "\n",
        "# 创建文档加载器\n",
        "loader = DocumentLoader(chunk_size=500, chunk_overlap=75)\n",
        "\n",
        "# 加载文档\n",
        "data_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), \"data\")\n",
        "file_path = os.path.join(data_dir, \"hr_policy.txt\")\n",
        "\n",
        "chunks = loader.load_and_split(file_path)\n",
        "\n",
        "print(f\"\\n总共生成 {len(chunks)} 个文本块\")\n",
        "print(f\"\\n第一个文本块预览：\")\n",
        "print(chunks[0].page_content[:300])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 向量化与存储\n",
        "\n",
        "### 3.1 理解Embedding向量化\n",
        "\n",
        "Embedding将文本转换为高维向量，使语义相似的文本在向量空间中距离更近。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from vector_store import VectorStoreManager\n",
        "\n",
        "# 创建向量存储管理器\n",
        "vector_manager = VectorStoreManager(embedding_model=\"text-embedding-3-small\")\n",
        "\n",
        "# 创建向量存储\n",
        "vector_store = vector_manager.create_vector_store(chunks)\n",
        "\n",
        "print(\"\\n✅ 向量存储创建完成！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. RAG链实现\n",
        "\n",
        "### 4.1 完整的RAG流程\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rag_chain import RAGChain\n",
        "\n",
        "# 创建RAG链\n",
        "rag = RAGChain(vector_manager, model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "# 测试问题\n",
        "question = \"年假如何申请？需要提前几天？\"\n",
        "\n",
        "print(f\"问题: {question}\")\n",
        "print(\"\\n执行RAG流程...\")\n",
        "\n",
        "result = rag.invoke(question, k=3)\n",
        "\n",
        "print(f\"\\n回答:\")\n",
        "print(result['answer'])\n",
        "print(f\"\\n参考文档数量: {len(result['retrieved_docs'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 总结\n",
        "\n",
        "通过这个项目，你学会了：\n",
        "\n",
        "1. ✅ **文档处理**：加载、分块、预处理\n",
        "2. ✅ **向量化**：Embedding模型的使用\n",
        "3. ✅ **向量存储**：FAISS的使用\n",
        "4. ✅ **检索**：相似度搜索\n",
        "5. ✅ **生成**：Prompt工程和LLM调用\n",
        "6. ✅ **RAG流程**：端到端的实现\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
